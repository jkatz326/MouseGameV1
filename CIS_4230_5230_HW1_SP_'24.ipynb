{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jkatz326/MouseGameV1/blob/main/CIS_4230_5230_HW1_SP_'24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5oITOi6OlUs"
      },
      "source": [
        "Welcome to the first coding assignment for CIS 4230/5230. In this assignment, we will be going over the basics of tools used for ML as well as beginning our journey in fair ML.\n",
        "\n",
        "\n",
        "Logistics:\n",
        "* Due: Wednesday, February 28th, 2024\n",
        "* PTS: 57\n",
        "\n",
        "**INDIVIDUAL WORK ONLY**\n",
        "\n",
        "Keep in mind that the Free Response Questions here are similar to ones you'll be asked on the exams, and you won't have access to ChatGPT then, so it's in your own interest to learn how to answer them yourself now.\n",
        "\n",
        "\n",
        "There are a few packages we will use intimately during this course that you will want to become familiar with:\n",
        "\n",
        "* [pandas](https://pandas.pydata.org/) - A package for dealing with datasets nicely\n",
        "* [NumPy](https://numpy.org/doc/stable/index.html) - The underpinnings of every ML matrix operation. NumPy is extremely fast but less user friendly.\n",
        "* [scikit-learn](https://scikit-learn.org/stable/index.html) - A user friendly package for tabular ML.\n",
        "* [folktables](https://github.com/zykls/folktables) - Census dataset loader\n",
        "\n",
        "If you have questions during the homework about any of these packages, look through the documentation before sending TA's questions. An important skill is being able to debug your own code, and as TA's, **it is NOT OUR JOB TO DEBUG IT FOR YOU, NOR WILL WE**. Conceptual questions are completely fair game, but \"why isn't this working\" is not. If you can't figure out how to get a certain slicing of data in NumPy, a google search will do you wonders (and is exactly what we would have to do to debug it anyway).\n",
        "\n",
        "The only package that is not standard loaded on Google Colab is Folktables. You can pip install the package with the following command."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu-nBVs8WfDy"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOgaJ9jOOmZX"
      },
      "outputs": [],
      "source": [
        "!pip install penngrader-client\n",
        "!pip install folktables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXWFkkfwOs3P"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import folktables as folk\n",
        "from penngrader.grader import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcDIMBjMOyOL"
      },
      "outputs": [],
      "source": [
        "### TODO (0 PTS) ###\n",
        "\n",
        "# Enter your 8 digit Pennkey here:\n",
        "STUDENT_ID = 12345678\n",
        "SECRET = STUDENT_ID\n",
        "\n",
        "# Enter your full name here (as a string):\n",
        "name = \"First Last\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RN2fvjOYBDq2"
      },
      "outputs": [],
      "source": [
        "#Run this block\n",
        "%%writefile config.yaml\n",
        "\n",
        "grader_api_url: 'https://23whrwph9h.execute-api.us-east-1.amazonaws.com/default/Grader23'\n",
        "grader_api_key: 'flfkE736fA6Z8GxMDJe2q8Kfk8UDqjsG3GVqOFOa'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkxuCgpnBDq2"
      },
      "outputs": [],
      "source": [
        "# Initialize penngrader\n",
        "grader = PennGrader('config.yaml', 'cis5230_sp24_HW1', STUDENT_ID, SECRET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnRPQHwAX0Yp"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aruRVKqvSbCf"
      },
      "source": [
        "From folktables, you are going to be using 2018 census data from Arizona to try and predict if an individual makes above or below $50,000 annually. This type of problem is known as 'binary classification'. The cells below will import the data into a pandas dataframe and split it into train + test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2dhtwFjWie0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jfh8q3U3ShWV"
      },
      "outputs": [],
      "source": [
        "# Import data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_source = folk.ACSDataSource(survey_year = '2018', horizon = '5-Year', survey = 'person')\n",
        "acs_data = data_source.get_data(states = [\"AZ\"], download = True)\n",
        "data_np, labels, _ = folk.ACSIncome.df_to_numpy(acs_data)\n",
        "data = pd.DataFrame(data_np, columns = ['AGEP',\n",
        "                                        'COW',\n",
        "                                        'SCHL',\n",
        "                                        'MAR',\n",
        "                                        'OCCP',\n",
        "                                        'POBP',\n",
        "                                        'RELP',\n",
        "                                        'WKHP',\n",
        "                                        'SEX',\n",
        "                                        'RAC1P'])\n",
        "# Split data\n",
        "x_train, x_test, y_train, y_test = train_test_split(data,\n",
        "                                                    labels,\n",
        "                                                    test_size = .2,\n",
        "                                                    random_state = 99)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF-viB0kSoI-"
      },
      "source": [
        "You can view the first n entries of a pandas dataframe using X.head(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKZJXuwtSuj6"
      },
      "outputs": [],
      "source": [
        "# View\n",
        "x_train.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wRH7aILTOG8"
      },
      "source": [
        "Each row is an individual, and each column represents a feature of the individual. You can see the exact data dictionary for columns here, but here's a general snapshot of what columns represent:\n",
        "\n",
        "* 'AGEP' -> Age\n",
        "* 'COW' -> Class of Worker\n",
        "* 'SCHL' -> Education Level\n",
        "* 'MAR' -> Marital Status\n",
        "* 'OCCP' -> Occupation\n",
        "* 'POBP' -> Place of Birth\n",
        "* 'RELP' -> Relationship\n",
        "* 'WKHP' -> Work Hours per Week\n",
        "* 'SEX' -> Binary Sex\n",
        "* 'RAC1P' -> Race\n",
        "\n",
        "What about the labels? And how many instances are in our dataset? Number of features? Class balance?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-UEGqIHThOo"
      },
      "outputs": [],
      "source": [
        "# View\n",
        "print(f'First fifteen training labels: {y_train[0:15]}')\n",
        "print(f'# of instances in x_train: {x_train.shape[0]}')\n",
        "print(f'# of features in x_train: {x_train.shape[1]}')\n",
        "print(f'Number of True values in training labels: {y_train.sum()}')\n",
        "print(f'Number of False values in training labels: {len(y_train) - y_train.sum()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGTXKDlJTbjF"
      },
      "source": [
        "Looking at this type of information is generally the first thing you should examine in a dataset when performaning EDA (exploratory data analysis). Other factors you may want to consider is the type of features (categorical, ordinal, real value), range of feature values, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VkmcopoUAQO"
      },
      "outputs": [],
      "source": [
        "### TODO ### (2 PTS)\n",
        "\n",
        "# get the first 15 individuals of x_train\n",
        "x_train_15 = # Your Code Here\n",
        "\n",
        "# get individuals 15 thru 30 of x_train\n",
        "x_train_slice = # Your Code Here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYAuYk2OUkr5"
      },
      "outputs": [],
      "source": [
        "# View\n",
        "print(x_train_15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmFdsN9JVACV"
      },
      "outputs": [],
      "source": [
        "# View\n",
        "print(x_train_slice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55cku6VSBDq4"
      },
      "outputs": [],
      "source": [
        "### DONT CHANGE THIS CELL\n",
        "grader.grade(test_case_id = 'check_train', answer = (x_train_15.to_numpy(), x_train_slice.to_numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxxOnce7T3ms"
      },
      "source": [
        "Instead of getting rows, you may (will) need to get columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAQCi5DjUYiO"
      },
      "outputs": [],
      "source": [
        "### TODO ### (2 Pts)\n",
        "\n",
        "# select the first 15 individuals in x_train age column\n",
        "x_train_age = # Your Code Here\n",
        "\n",
        "\n",
        "# select the first 15 individuals in x_train education column\n",
        "x_train_school = # Your Code Here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoeUDVh8BX0o"
      },
      "outputs": [],
      "source": [
        "x_train_age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HgpfMA9BDq4"
      },
      "outputs": [],
      "source": [
        "x_train_school"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeIQyZTTBDq4"
      },
      "outputs": [],
      "source": [
        "grader.grade(test_case_id = 'check_train_age_school', answer = (np.array(x_train_age), np.array(x_train_school)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnqSoX2-Ud7T"
      },
      "outputs": [],
      "source": [
        "# View\n",
        "print(x_train_age)\n",
        "print(type(x_train_age))\n",
        "print(x_train_age.to_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meWAvP4AVGdy"
      },
      "outputs": [],
      "source": [
        "# View\n",
        "print(x_train_school)\n",
        "print(type(x_train_school))\n",
        "print(x_train_school.to_numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaJPsl6fVSp-"
      },
      "source": [
        "While it is fun to get whole columns or rows, it is much more useful to get rows based on some value in a specified column. For example,what if we want to get all male or female individuals in this dataset?\n",
        "\n",
        "The same function that let you look at columns will let you create a boolean True/False indicator function by specifying X.column_name == value or X['column_name] == value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjeEBbNVVTok"
      },
      "outputs": [],
      "source": [
        "# Example\n",
        "print(x_train.SEX == 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9okhL_FIVlCr"
      },
      "source": [
        "Create functions that define the following four groups:\n",
        "\n",
        "individuals identified as white\n",
        "individuals identified as black\n",
        "individuals identified as male\n",
        "individuals identified as female\n",
        "You will use these functions later on in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2MNeP7UVjU3"
      },
      "outputs": [],
      "source": [
        "#Todo (8 PTS)\n",
        "\n",
        "def g_white(X):\n",
        "  '''Indicator function which returns boolean True/False\n",
        "   for individuals identified as white'''\n",
        "  indices = # Your Code Here\n",
        "\n",
        "  return indices\n",
        "\n",
        "def g_black(X):\n",
        "    '''Indicator function which returns boolean True/False\n",
        "     for individuals identified as black'''\n",
        "    indices = # Your Code Here\n",
        "\n",
        "    return indices\n",
        "\n",
        "\n",
        "def g_male(X):\n",
        "    '''Indicator function which returns boolean True/False\n",
        "     for individuals identified as male'''\n",
        "    indices = # Your Code Here\n",
        "\n",
        "    return indices\n",
        "\n",
        "\n",
        "def g_female(X):\n",
        "    '''Indicator function which returns boolean True/False\n",
        "     for individuals identified as female'''\n",
        "    indices = # Your Code Here\n",
        "\n",
        "    return indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1LOvMg0WDhs"
      },
      "outputs": [],
      "source": [
        "# Don't modify this cell but run it :)\n",
        "white_indices = g_white(x_train_15)\n",
        "black_indices = g_black(x_train_15)\n",
        "male_indices = g_male(x_train_15)\n",
        "female_indices = g_female(x_train_15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFQvouz-BDq5"
      },
      "outputs": [],
      "source": [
        "# Don't modify this cell but run it :)\n",
        "white_indices_num = g_white(x_train).sum()\n",
        "black_indices_num = g_black(x_train).sum()\n",
        "male_indices_num = g_male(x_train).sum()\n",
        "female_indices_num = g_female(x_train).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hS40AzniBDq5"
      },
      "outputs": [],
      "source": [
        "grader.grade(test_case_id = 'check_white_indices', answer = (white_indices.to_numpy(), white_indices_num))\n",
        "grader.grade(test_case_id = 'check_black_indices', answer = (black_indices.to_numpy(), black_indices_num))\n",
        "grader.grade(test_case_id = 'check_male_indices', answer = (male_indices.to_numpy(), male_indices_num))\n",
        "grader.grade(test_case_id = 'check_female_indices', answer = (female_indices.to_numpy(), female_indices_num))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mlc6Ty-8WvCU"
      },
      "source": [
        "Your group indicator functions return boolean True/False values, but you may want the slice from the dataframe defined by indicator function. Pandas lets you slice data using indicator functions by doing X[True/False series].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTqHgpDpWwmD"
      },
      "outputs": [],
      "source": [
        "### TODO ### (3 PTS)\n",
        "\n",
        "# write a function which accepts a dataframe X and group g and returns the subset of individuals who are a part of group g\n",
        "def group_data(X, g):\n",
        "    # Your Code Here\n",
        "\n",
        "    return X_subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TzNxpZnXDlb"
      },
      "outputs": [],
      "source": [
        "# Don't modify this cell but run it :)\n",
        "data = group_data(x_train[0:15], g_white)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0M9ylRKBDq5"
      },
      "outputs": [],
      "source": [
        "grader.grade(test_case_id = 'check_group_data', answer = data.to_numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXLhwdK-V_nb"
      },
      "source": [
        "Given the feature space of a dataset, the number of groups you can define grows exponentially. If you have  ùëë  features which can take on 2 values each, then\n",
        "\n",
        "**|unique groups| =  $2^ùëë$**\n",
        "\n",
        "However, in many datasets such as this one, the number of values each feature can take on is larger than 2. The cell below will show the number of groups that can be made given that feature values are exactly some value (i.e. not including a group where age < 40, but includes age = 40)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdqwl653XkAq",
        "outputId": "d63f6756-3337-4c4f-b4e2-116e49ccd3d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique groups: 268070803153920\n"
          ]
        }
      ],
      "source": [
        "# Number of unique groups\n",
        "print(f'Number of unique groups: {np.prod(x_train.nunique())}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9qCBC3_XozP"
      },
      "source": [
        "Clearly there are a lot of unique groups in this dataset, going down to the individual defining their own group (unless there are two individuals with identical feature values in the dataset). The groups you defined above were quite large, check the sizes in the training data for each function using your earlier group functions. You will need to determine how to get the number of True values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiSt8wkTXqed"
      },
      "outputs": [],
      "source": [
        "### TODO ### (4 Pts)\n",
        "\n",
        "# find number of individuals identified as white in x_train\n",
        "\n",
        "size_train_white = 0\n",
        "# Your Code Here\n",
        "\n",
        "\n",
        "\n",
        "# find number of individuals identified as black in x_train\n",
        "size_train_black = 0\n",
        "# Your Code Here\n",
        "\n",
        "\n",
        "\n",
        "# find number of individuals identified as male in x_train\n",
        "size_train_male = 0\n",
        "# Your Code Here\n",
        "\n",
        "\n",
        "# find number of individuals identified as female in x_train\n",
        "size_train_female = 0\n",
        "# Your Code Here\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RH9dcdYNXw57"
      },
      "outputs": [],
      "source": [
        "# View\n",
        "print(\"# of white individuals = \" + str(size_train_white))\n",
        "print(\"# of black individuals = \" + str(size_train_black))\n",
        "print(\"# of men = \" + str(size_train_male))\n",
        "print(\"# of women = \"  + str(size_train_female))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_POuO1JBDq6"
      },
      "outputs": [],
      "source": [
        "grader.grade(test_case_id = 'check_size_train_white', answer = size_train_white)\n",
        "grader.grade(test_case_id = 'check_size_train_black', answer = size_train_black)\n",
        "grader.grade(test_case_id = 'check_size_train_male', answer = size_train_male)\n",
        "grader.grade(test_case_id = 'check_size_train_female', answer = size_train_female)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPaXF_OGYeHI"
      },
      "source": [
        "**FRQ 1:**\n",
        "\n",
        "What do you notice about the number of individuals that fall within each category? How can this effect the model's performance on specific groups of people? Answer in 1-2 Paragraphs. (5 PTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4RJHwEQY4aM"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygRF-qWdY5QD"
      },
      "source": [
        "It is worth noting you can immediately make more groups using logical AND/OR to create intersection and unions of the boolean indicator functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMu-SyNeZNlc"
      },
      "outputs": [],
      "source": [
        "### TODO ### (2 PTS)\n",
        "\n",
        "# get boolean indices of individuals who are indentified as white OR black in x_train_15\n",
        "indices_black_or_white = # Your Code Here\n",
        "\n",
        "\n",
        "# get boolean indices of individuals who are indentified as white AND male in x_train_15\n",
        "indices_white_and_male = # Your Code Here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ood5poRpZaBQ"
      },
      "outputs": [],
      "source": [
        "#Run but do not modify\n",
        "grader.grade(test_case_id = 'check_black_white', answer = indices_black_or_white.to_numpy())\n",
        "grader.grade(test_case_id = 'check_white_male', answer = indices_white_and_male.to_numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuImm2uyZmoz"
      },
      "source": [
        "We've gone over the basics of Pandas dataframes to look at/slice dataframes, but how do we create preditive models using this data? Well, we want to minimize an objective function over a hypothesis class using an optimization method while having good generalization. Training a decision tree or a neural network both follow this procedure, but one is much more complicated. This course is not designed to show you methods which complete this optimization task (CIS 5190/5200 would be better if you are looking for that), but rather to see/measure/fix the shortcomings of this method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlNCBOGpYy1m"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGivuIrrYwgT"
      },
      "source": [
        "Time to train some models.\n",
        "\n",
        "Below we give the generic pipeline for training a ML model on tabular dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhtidFVLZuJm"
      },
      "outputs": [],
      "source": [
        "# import decision tree classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# import loss function\n",
        "from sklearn.metrics import zero_one_loss as loss_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIYz04xOZz4s"
      },
      "source": [
        "The loss function we will be using is the zero-one loss, also known as hit loss. It is defined as\n",
        "* $\\frac{1}{n}\\sum_{i = 1}^{n} I(\\hat{y} \\neq y)$\n",
        "\n",
        "where $ùë¶$ is the true value, $ùë¶ÃÇ$  is the predicted value, $ùëõ$ is the number of samples, and ùêº is indicator function.\n",
        "\n",
        "More simplistically, hit loss is the percentage of time your model makes the incorrect prediction.\n",
        "\n",
        "Here is an example of training a depth 3 decision tree. Note that we fit our model on the training samples, and then predict on both the train and test data. Viewing both errors will give you a sense of how your model is generalizing, and is usually done with a validation vice a test set since you gain information about the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRveJ5xNaVYc"
      },
      "outputs": [],
      "source": [
        "### Generic ML Pipeline ###\n",
        "\n",
        "# Define hypothesis class: decision trees with max depth 3\n",
        "clf = DecisionTreeClassifier(max_depth = 3, random_state = 42)\n",
        "\n",
        "# Minimize zero one loss using training data\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "# Get train/test predictions from trained hypothesis\n",
        "train_predictions = clf.predict(x_train)\n",
        "test_predictions = clf.predict(x_test)\n",
        "\n",
        "# Compute train/test error\n",
        "train_error = loss_fn(y_train, train_predictions)\n",
        "test_error = loss_fn(y_test, test_predictions)\n",
        "\n",
        "# Print errors\n",
        "print(f'Train Error: {train_error:.2%}')\n",
        "print(f'Test Error: {test_error:.2%}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAMKZSt6aidI"
      },
      "source": [
        "Both train and test errors are roughly equivalent, though pretty high. What happens when you train a deeper decision tree, say of depth 12?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drrNWfeBahZL"
      },
      "outputs": [],
      "source": [
        "### TODO ### (3 PTS)\n",
        "\n",
        "### MUST SET RANDOM_STATE = 99 ###\n",
        "\n",
        "# define hypothesis class of max depth 12 decision trees decision, fit the model, and record train and test errors\n",
        "# Your Code Here\n",
        "\n",
        "\n",
        "# print errors\n",
        "print(f'Train Error: {dt_12_train_error:.2%}')\n",
        "print(f'Test Error: {dt_12_test_error:.2%}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_yE6wHZBDq8"
      },
      "outputs": [],
      "source": [
        "#Run but do not modify\n",
        "grader.grade(test_case_id = 'check_dt_12_train_test_error', answer = (dt_12_train_error, dt_12_test_error))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9DSl8kabG7l"
      },
      "source": [
        "Notice both train and test error have decreased, but a bit of separation between the two has occurred. Now what happens in an extremely complex hypothesis space?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaHIdGzbbL0R"
      },
      "outputs": [],
      "source": [
        "### TODO ### (3 Pts)\n",
        "\n",
        "### MUST SET RANDOM_STATE = 99 ###\n",
        "\n",
        "# define hypothesis class of max depth 29 decision trees decision, and record train and test errors\n",
        "# Your Code Here\n",
        "\n",
        "# print errors\n",
        "print(f'Train Error: {dt_29_train_error:.2%}')\n",
        "print(f'Test Error: {dt_29_test_error:.2%}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQQjRMRtBDq8"
      },
      "outputs": [],
      "source": [
        "#Run but do not modify\n",
        "grader.grade(test_case_id = 'check_dt_29_train_test_error', answer = (dt_29_train_error, dt_29_test_error))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urVL5IGEbQBC"
      },
      "source": [
        "**FRQ 2:**\n",
        "\n",
        "Now there is a drastic difference between the two!\n",
        "Define model overfitting, and analyze whether or not this model is overfit to the training data. Answer in 2-3 sentences. (2 PTS)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FYI0osZbmT6"
      },
      "source": [
        "**Answer:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZhkvuLyBDq9"
      },
      "outputs": [],
      "source": [
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh_MNp8Hb-3t"
      },
      "outputs": [],
      "source": [
        "# About 30 seconds to run\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "train_error_list = []\n",
        "test_error_list = []\n",
        "\n",
        "def test_train_graph(errors_dict, title='Blank', x_axis = 'Rounds', y_axis = 'Error'):\n",
        "    random_set = list(errors_dict.values())[0]\n",
        "    x = np.linspace(1, len(random_set), len(random_set))\n",
        "    errors_dict['axis'] = x\n",
        "    graph_df = pd.DataFrame.from_dict(errors_dict)\n",
        "\n",
        "    graph_df_melted = graph_df.melt('axis',var_name = 'Errors Set', value_name = 'Error')\n",
        "\n",
        "    ### SET GRAPHS LABELS HERE ###\n",
        "    xaxis =  x_axis\n",
        "    yaxis =  y_axis\n",
        "\n",
        "    plt.figure(figsize = (15,10))\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    sns_plt = sns.lineplot(data=graph_df_melted, x='axis', y='Error', hue='Errors Set')\n",
        "    sns_plt.set_title(title, fontsize = 15)\n",
        "    sns_plt.set_xlabel(xaxis, fontsize = 13)\n",
        "    sns_plt.set_ylabel(yaxis, fontsize = 13)\n",
        "    sns_plt.legend(bbox_to_anchor=(.98, 1))\n",
        "    plt.show(block=False)\n",
        "\n",
        "for i in range(1, 30):\n",
        "    clf = DecisionTreeClassifier(max_depth = i, random_state = 42)\n",
        "    clf.fit(x_train, y_train)\n",
        "\n",
        "    train_predictions = clf.predict(x_train)\n",
        "    test_predictions = clf.predict(x_test)\n",
        "\n",
        "    train_error = loss_fn(y_train, train_predictions)\n",
        "    test_error = loss_fn(y_test, test_predictions)\n",
        "\n",
        "    train_error_list.append(train_error)\n",
        "    test_error_list.append(test_error)\n",
        "\n",
        "test_train_graph({\"Train Error\":train_error_list, \"Test Error\":test_error_list}, title = 'Error on Decision Trees as Max Depth Increases', x_axis = 'Depth', y_axis = 'Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e84B-J1OcZPh"
      },
      "outputs": [],
      "source": [
        "### TODO ### (3 Points)\n",
        "\n",
        "# put integer depth of underfitting (answer is a range, no exact answer expected)\n",
        "underfitting_depth = # Your Code Here\n",
        "\n",
        "\n",
        "# put integer depth good generalization (answer is a range, no exact answer expected)\n",
        "good_generalization_depth = # Your Code Here\n",
        "\n",
        "\n",
        "# put integer depth of overfitting (answer is a range, no exact answer expected)\n",
        "overfitting_depth = # Your Code Here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hefGWgy3BDq9"
      },
      "outputs": [],
      "source": [
        "#Run but do not modify\n",
        "grader.grade(test_case_id = 'check_fitting_depth', answer = (underfitting_depth, good_generalization_depth, overfitting_depth))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEEhhOe2b1At"
      },
      "source": [
        "Using the framework above, train a decision tree classifier which has the best out of sample performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRXPYq5rc6og"
      },
      "outputs": [],
      "source": [
        "### TODO ### (1 Point)\n",
        "\n",
        "### MUST SET RANDOM_STATE = 99 ###\n",
        "### MUST SET MAX DEPTH TO 10 ###\n",
        "\n",
        "# train a decision tree classifier\n",
        "# Your Code Here\n",
        "\n",
        "# We will manually grade this problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on3tORyMaGNJ"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ4QjuPedHk0"
      },
      "source": [
        "Great, now that you've created a model, it's time to evaluate how it does on different metrics.\n",
        "\n",
        "Write two functions that calculate the following:\n",
        "* False Postive Rate = $\\frac{FP}{FP + TN}$\n",
        "* False Negative Rate = $\\frac{FN}{FN + TP}$\n",
        "\n",
        "where FP is false positive, FN is false negative, TP is true positive, and TN is true negative.\n",
        "\n",
        "A useful function you may want to look at is sklearn's confusion matrix..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrO8ZDiSdIfD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gaiN61kdOJJ"
      },
      "outputs": [],
      "source": [
        "### TODO ### (0 Pts) *We will test this in the next section*\n",
        "\n",
        "# write function which returns false positive rate given true y and predicted y\n",
        "def FPR(y_true, y_pred):\n",
        "    # Your Code Here\n",
        "    return fpr\n",
        "\n",
        "# write function which returns false negative rate given true y and predicted y\n",
        "def FNR(y_true, y_pred):\n",
        "    # Your Code Here\n",
        "\n",
        "    return fnr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEp__t6IdQfM"
      },
      "outputs": [],
      "source": [
        "### TODO ### (7 Pts)\n",
        "\n",
        "# compute false positive rate on dt_clf (A range of answers will be accepted)\n",
        "fpr_test = # Your Code Here\n",
        "\n",
        "\n",
        "# compute false negative rate on dt_clf (A range of answers will be accepted)\n",
        "fnr_test = # Your Code Here\n",
        "\n",
        "\n",
        "print(f'Test false positive rate: {fpr_test}')\n",
        "print(f'Test false negative rate: {fnr_test}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68xxzsJzBDq-"
      },
      "outputs": [],
      "source": [
        "grader.grade(test_case_id = 'check_fpr_test', answer = (fpr_test))\n",
        "grader.grade(test_case_id = 'check_fnr_test', answer = (fnr_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M38Jr2YCdvUB"
      },
      "source": [
        "Is this a high false positive rate? Low? High/low false negative rate? Is this a bad thing?\n",
        "\n",
        "This questions often times depend entirely on the underlying problem. Suppose we are in a medical setting where a ML model is making predictions on whether an image of a tumor determines benign (0) or cancerous (1).\n",
        "\n",
        "A high false positive rate implies that your model ofetn says an image is cancerous when it is in fact not. This isn't so bad; the image gets flagged as cancerous and then gets sent to the doctor who says the computer lied and the patient is relieved.\n",
        "\n",
        "A high false negative rate in this case is much more dangerous: an image often times passes through as non-cancerous when it is in fact cancerous. If the doctor only looks at images which are flagged as cancerous, this model places the person in danger.\n",
        "\n",
        "In the census data setting, you can imagine this is a consumer lending model where if someone makes more than $50,000 annually, they will get a loan. But knowing an overall model has high/low FPR/FNR only gives you a general idea of places the model can go wrong. But you can measure well-defined groups FPR/FNR as well.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AplepflteB7b"
      },
      "outputs": [],
      "source": [
        "# Make FPR calculations possible (Run this block without modifying anything)\n",
        "\n",
        "white_test = group_data(x_test, g_white)\n",
        "white_true = y_test[g_white(x_test)]\n",
        "white_pred = dt_best_clf.predict(white_test)\n",
        "black_true = y_test[g_black(x_test)]\n",
        "print(black_true.size)\n",
        "print(white_true.size)\n",
        "black_test = group_data(x_test, g_black)\n",
        "black_pred = dt_best_clf.predict(black_test)\n",
        "male_true = y_test[g_male(x_test)]\n",
        "male_test = group_data(x_test, g_male)\n",
        "male_pred = dt_best_clf.predict(male_test)\n",
        "female_true = y_test[g_female(x_test)]\n",
        "female_test = group_data(x_test, g_female)\n",
        "female_pred = dt_best_clf.predict(female_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToVqB9mJeG0_"
      },
      "outputs": [],
      "source": [
        "### TODO ### (4 PTS)\n",
        "\n",
        "# Compute the FPR for individuals identified as white on test data\n",
        "fpr_white = # Your Code Here\n",
        "\n",
        "\n",
        "# Compute the FPR for individuals identified as black on test data\n",
        "fpr_black = # Your Code Here\n",
        "\n",
        "\n",
        "# Compute the FPR for individuals identified as male on test data\n",
        "fpr_male = # Your Code Here\n",
        "\n",
        "# Compute the FPR for individuals identified as female on test data\n",
        "fpr_female = # Your Code Here\n",
        "\n",
        "\n",
        "print(f'FPR individuals (white): {fpr_white}')\n",
        "print(f'FPR individuals (black): {fpr_black}')\n",
        "print(f'FPR individuals (male): {fpr_male}')\n",
        "print(f'FPR individuals (female): {fpr_female}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtOf32UcBDq-"
      },
      "outputs": [],
      "source": [
        "grader.grade(test_case_id = 'check_fpr_white', answer = (fpr_white))\n",
        "grader.grade(test_case_id = 'check_fpr_black', answer = (fpr_black))\n",
        "grader.grade(test_case_id = 'check_fpr_male', answer = (fpr_male))\n",
        "grader.grade(test_case_id = 'check_fpr_female', answer = (fpr_female))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtgklW3revf3"
      },
      "source": [
        "Note that the only group drastically far away from the model's overall FPR is individuals identified as females, which is significantly lower.\n",
        "\n",
        "\n",
        "\n",
        "What about FNR?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFv0kTDiemUX"
      },
      "outputs": [],
      "source": [
        "### TODO ### (4 PTS)\n",
        "\n",
        "# Compute the FNR for individuals identified as white on test data\n",
        "fnr_white = # Your Code Here\n",
        "\n",
        "\n",
        "# Compute the FNR for individuals identified as black on test data\n",
        "fnr_black = # Your Code Here\n",
        "\n",
        "\n",
        "# Compute the FNR for individuals identified as male on test data\n",
        "fnr_male = # Your Code Here\n",
        "\n",
        "# Compute the FNR for individuals identified as female on test data\n",
        "fnr_female = # Your Code Here\n",
        "\n",
        "\n",
        "print(f'FNR individuals (white): {fnr_white}')\n",
        "print(f'FNR individuals (black): {fnr_black}')\n",
        "print(f'FNR individuals (male): {fnr_male}')\n",
        "print(f'FNR female individuals (female): {fnr_female}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbWgeQ9vBDq_"
      },
      "outputs": [],
      "source": [
        "grader.grade(test_case_id = 'check_fnr_white', answer = (fnr_white))\n",
        "grader.grade(test_case_id = 'check_fnr_black', answer = (fnr_black))\n",
        "grader.grade(test_case_id = 'check_fnr_male', answer = (fnr_male))\n",
        "grader.grade(test_case_id = 'check_fnr_female', answer = (fnr_female))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1HZsUYzjgJb"
      },
      "source": [
        "Looking at the FPR and FNR metrics on different groups is one way of quickly checking for bias. But let's plot out the AUC-ROC curves as described in Northpointe's response to ProPublica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8FiGL-wjXh9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOBvgCR-j94K"
      },
      "outputs": [],
      "source": [
        "# Run this block without modifying anything\n",
        "y_score_male = dt_best_clf.predict_proba(male_test)[:, 1]\n",
        "\n",
        "FPR_MALE, TPR_MALE, _ = roc_curve(male_true, y_score_male)\n",
        "roc_auc = auc(FPR_MALE, TPR_MALE)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(FPR_MALE, TPR_MALE, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC for male subgroup')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vORTDbZk8dZ"
      },
      "outputs": [],
      "source": [
        "# Run this block without modifying anything\n",
        "y_score_female = dt_best_clf.predict_proba(female_test)[:, 1]\n",
        "\n",
        "FPR_FEMALE, TPR_FEMALE, _ = roc_curve(female_true, y_score_female)\n",
        "roc_auc = auc(FPR_FEMALE, TPR_FEMALE)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(FPR_FEMALE, TPR_FEMALE, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC for female subgroup')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdgAIefVlDwc"
      },
      "outputs": [],
      "source": [
        "# Run this block without modifying anything\n",
        "y_score_white = dt_best_clf.predict_proba(white_test)[:, 1]\n",
        "\n",
        "FPR_WHITE, TPR_WHITE, _ = roc_curve(white_true, y_score_white)\n",
        "roc_auc = auc(FPR_WHITE, TPR_WHITE)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(FPR_WHITE, TPR_WHITE, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC for white subgroup')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1eSnU9rlJsu"
      },
      "outputs": [],
      "source": [
        "# Run this block without modifying anything\n",
        "y_score_black = dt_best_clf.predict_proba(black_test)[:, 1]\n",
        "\n",
        "FPR_BLACK, TPR_BLACK, _ = roc_curve(black_true, y_score_black)\n",
        "roc_auc = auc(FPR_BLACK, TPR_BLACK)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(FPR_BLACK, TPR_BLACK, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC for black subgroup')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCIyzC4qeQX6"
      },
      "source": [
        "**FRQ 3:**\n",
        "\n",
        "Why might black individuals have a significantly higher FNR than white individuals in this dataset? Answer in 2-3 sentences. (3 PTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NtYanQDa1Ud"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "*Write your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdFZRLfnbCWy"
      },
      "source": [
        "**FRQ 4:**\n",
        "\n",
        "Describe the effect abnormally high FNR in the context of a loan application. Answer in 2-3 sentences. (3 PTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2ymDOMSa_NU"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "*Write your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf4NEdzCbQun"
      },
      "source": [
        "**FRQ 5:**\n",
        "\n",
        "What do you notice about the ROC curve and AUC for each of the different subgroups? What does that say about the bias in the model? Answer in 2-3 sentences. (3 PTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nONY_8mxBDrA"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu9cSXs2gbrR"
      },
      "source": [
        "Submission Instructions:\n",
        "Stay tuned for Gradescope submission instructions!\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}